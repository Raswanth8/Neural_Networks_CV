{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GTSRB Sign Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(path_to_data, path_to_save_train, path_to_save_val, split_size=0.1):\n",
    "\n",
    "    folders = os.listdir(path_to_data)\n",
    "\n",
    "    for folder in folders:\n",
    "\n",
    "        full_path = os.path.join(path_to_data, folder)\n",
    "        images_paths = glob.glob(os.path.join(full_path, '*.png'))\n",
    "\n",
    "        x_train, x_val = train_test_split(images_paths, test_size=split_size)\n",
    "\n",
    "        for x in x_train:\n",
    "\n",
    "            path_to_folder = os.path.join(path_to_save_train, folder)\n",
    "\n",
    "            if not os.path.isdir(path_to_folder):\n",
    "                os.makedirs(path_to_folder)\n",
    "\n",
    "            shutil.copy(x, path_to_folder)\n",
    "\n",
    "        for x in x_val:\n",
    "\n",
    "            path_to_folder = os.path.join(path_to_save_val, folder)\n",
    "            if not os.path.isdir(path_to_folder):\n",
    "                os.makedirs(path_to_folder)\n",
    "\n",
    "            shutil.copy(x, path_to_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"C:\\\\Users\\\\\\RASWANTH.SR\\\\\\Desktop\\\\ML\\\\Neural Networks and Deep Learning\\\\Tensorflow for CV\\\\CSV\\\\Train\"\n",
    "path_to_save_train = \"C:\\\\Users\\\\RASWANTH.SR\\\\Desktop\\\\ML\\\\Neural Networks and Deep Learning\\\\Tensorflow for CV\\\\CSV\\\\training_data\\\\train\"\n",
    "path_to_save_val = \"C:\\\\Users\\\\RASWANTH.SR\\\\Desktop\\\\ML\\\\Neural Networks and Deep Learning\\\\Tensorflow for CV\\\\CSV\\\\training_data\\\\val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(path_to_data, path_to_save_train=path_to_save_train, path_to_save_val=path_to_save_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_test_set(path_to_images, path_to_csv):\n",
    "    try:\n",
    "        with open(path_to_csv, 'r') as csvfile:\n",
    "\n",
    "            reader = csv.reader(csvfile, delimiter=',')\n",
    "\n",
    "            for i, row in enumerate(reader):\n",
    "\n",
    "                if i==0:\n",
    "                    continue\n",
    "\n",
    "                img_name = row[-1].replace('Test/', '')\n",
    "                label = row[-2]\n",
    "\n",
    "                path_to_folder = os.path.join(path_to_images, label)\n",
    "\n",
    "                if not os.path.isdir(path_to_folder):\n",
    "                    os.makedirs(path_to_folder)\n",
    "\n",
    "                img_full_path = os.path.join(path_to_images, img_name)\n",
    "                shutil.move(img_full_path, path_to_folder)\n",
    "\n",
    "    except:\n",
    "        print('[INFO] : Error reading csv file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_images = \"C:\\\\Users\\\\RASWANTH.SR\\\\Desktop\\\\ML\\\\Neural Networks and Deep Learning\\\\Tensorflow for CV\\\\CSV\\\\Test\"\n",
    "path_to_csv = \"C:\\\\Users\\\\RASWANTH.SR\\\\Desktop\\\\ML\\\\Neural Networks and Deep Learning\\\\Tensorflow for CV\\\\CSV\\\\Test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_test_set(path_to_images, path_to_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D,Input,MaxPool2D,BatchNormalization,GlobalAvgPool2D,Dense,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def streets_sign_model(n_classes):\n",
    "    my_input = Input(shape =(60,60,3))\n",
    "    \n",
    "    x = Conv2D(32,(3,3),activation = 'relu')(my_input) \n",
    "    x = Conv2D(64,(3,3),activation = 'relu')(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(128,(3,3),activation = 'relu')(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64,activation = 'relu')(x)\n",
    "    x = Dense(n_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = tensorflow.keras.Model(inputs = my_input,outputs=x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 60, 60, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 58, 58, 32)        896       \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 56, 56, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 28, 28, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 28, 28, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 26, 26, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 13, 13, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 13, 13, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 21632)             0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                1384512   \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,479,178\n",
      "Trainable params: 1,478,794\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = streets_sign_model(10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generators(batch_size, train_data_path, val_data_path, test_data_path):\n",
    "\n",
    "    preprocessor = ImageDataGenerator(\n",
    "        rescale = 1 / 255.,\n",
    "    )\n",
    "\n",
    "    train_generator = preprocessor.flow_from_directory(\n",
    "        train_data_path,\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=(60,60),\n",
    "        color_mode='rgb',\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    val_generator = preprocessor.flow_from_directory(\n",
    "        val_data_path,\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=(60,60),\n",
    "        color_mode=\"rgb\",\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    test_generator = preprocessor.flow_from_directory(\n",
    "        test_data_path,\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=(60,60),\n",
    "        color_mode=\"rgb\",\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    return train_generator, val_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train = \"C:\\\\Users\\\\RASWANTH.SR\\\\Desktop\\\\ML\\\\Neural Networks and Deep Learning\\\\Tensorflow for CV\\\\CSV\\\\training_data\\\\train\"\n",
    "path_to_val = \"C:\\\\Users\\\\RASWANTH.SR\\\\Desktop\\\\ML\\\\Neural Networks and Deep Learning\\\\Tensorflow for CV\\\\CSV\\\\training_data\\\\val\"\n",
    "path_to_test = \"C:\\\\Users\\\\\\RASWANTH.SR\\\\\\Desktop\\\\ML\\\\Neural Networks and Deep Learning\\\\Tensorflow for CV\\\\CSV\\\\Test\"\n",
    "batch_size  = 64\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35288 images belonging to 43 classes.\n",
      "Found 3921 images belonging to 43 classes.\n",
      "Found 12630 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, val_generator, test_generator = create_generators(batch_size, path_to_train, path_to_val, path_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save_model = \"./Models\"\n",
    "ckpt_saver = ModelCheckpoint(\n",
    "    path_to_save_model,\n",
    "    monitor = 'val_accuracy',\n",
    "    mode ='max',\n",
    "    save_best_only =True,\n",
    "    save_freq='epoch',\n",
    "    verbose =1\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(monitor = 'val_accuracy', patience =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 0.4998 - accuracy: 0.8789\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.83168, saving model to .\\Models\n",
      "INFO:tensorflow:Assets written to: .\\Models\\assets\n",
      "552/552 [==============================] - 262s 473ms/step - loss: 0.4998 - accuracy: 0.8789 - val_loss: 0.6312 - val_accuracy: 0.8317\n",
      "Epoch 2/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 0.9844\n",
      "Epoch 00002: val_accuracy improved from 0.83168 to 0.97016, saving model to .\\Models\n",
      "INFO:tensorflow:Assets written to: .\\Models\\assets\n",
      "552/552 [==============================] - 277s 501ms/step - loss: 0.0545 - accuracy: 0.9844 - val_loss: 0.1065 - val_accuracy: 0.9702\n",
      "Epoch 3/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9904\n",
      "Epoch 00003: val_accuracy improved from 0.97016 to 0.97858, saving model to .\\Models\n",
      "INFO:tensorflow:Assets written to: .\\Models\\assets\n",
      "552/552 [==============================] - 283s 513ms/step - loss: 0.0319 - accuracy: 0.9904 - val_loss: 0.0940 - val_accuracy: 0.9786\n",
      "Epoch 4/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9919\n",
      "Epoch 00004: val_accuracy did not improve from 0.97858\n",
      "552/552 [==============================] - 276s 499ms/step - loss: 0.0281 - accuracy: 0.9919 - val_loss: 0.1356 - val_accuracy: 0.9633\n",
      "Epoch 5/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9890\n",
      "Epoch 00005: val_accuracy did not improve from 0.97858\n",
      "552/552 [==============================] - 275s 499ms/step - loss: 0.0429 - accuracy: 0.9890 - val_loss: 0.2061 - val_accuracy: 0.9572\n",
      "Epoch 6/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9953\n",
      "Epoch 00006: val_accuracy improved from 0.97858 to 0.98011, saving model to .\\Models\n",
      "INFO:tensorflow:Assets written to: .\\Models\\assets\n",
      "552/552 [==============================] - 300s 543ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 0.0889 - val_accuracy: 0.9801\n",
      "Epoch 7/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9943\n",
      "Epoch 00007: val_accuracy did not improve from 0.98011\n",
      "552/552 [==============================] - 282s 512ms/step - loss: 0.0245 - accuracy: 0.9943 - val_loss: 0.1671 - val_accuracy: 0.9658\n",
      "Epoch 8/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9940\n",
      "Epoch 00008: val_accuracy improved from 0.98011 to 0.98546, saving model to .\\Models\n",
      "INFO:tensorflow:Assets written to: .\\Models\\assets\n",
      "552/552 [==============================] - 377s 682ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0765 - val_accuracy: 0.9855\n",
      "Epoch 9/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 0.9941\n",
      "Epoch 00009: val_accuracy improved from 0.98546 to 0.98929, saving model to .\\Models\n",
      "INFO:tensorflow:Assets written to: .\\Models\\assets\n",
      "552/552 [==============================] - 453s 821ms/step - loss: 0.0286 - accuracy: 0.9941 - val_loss: 0.0726 - val_accuracy: 0.9893\n",
      "Epoch 10/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9951\n",
      "Epoch 00010: val_accuracy did not improve from 0.98929\n",
      "552/552 [==============================] - 451s 817ms/step - loss: 0.0202 - accuracy: 0.9951 - val_loss: 0.0777 - val_accuracy: 0.9885\n",
      "Epoch 11/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9966\n",
      "Epoch 00011: val_accuracy did not improve from 0.98929\n",
      "552/552 [==============================] - 451s 817ms/step - loss: 0.0138 - accuracy: 0.9966 - val_loss: 0.1235 - val_accuracy: 0.9842\n",
      "Epoch 12/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9968\n",
      "Epoch 00012: val_accuracy did not improve from 0.98929\n",
      "552/552 [==============================] - 451s 816ms/step - loss: 0.0141 - accuracy: 0.9968 - val_loss: 0.0721 - val_accuracy: 0.9885\n",
      "Epoch 13/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9971\n",
      "Epoch 00013: val_accuracy did not improve from 0.98929\n",
      "552/552 [==============================] - 451s 818ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.2699 - val_accuracy: 0.9666\n",
      "Epoch 14/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9961\n",
      "Epoch 00014: val_accuracy did not improve from 0.98929\n",
      "552/552 [==============================] - 445s 806ms/step - loss: 0.0161 - accuracy: 0.9961 - val_loss: 0.0790 - val_accuracy: 0.9865\n",
      "Epoch 15/15\n",
      "552/552 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9965\n",
      "Epoch 00015: val_accuracy did not improve from 0.98929\n",
      "552/552 [==============================] - 450s 815ms/step - loss: 0.0173 - accuracy: 0.9965 - val_loss: 0.0743 - val_accuracy: 0.9885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b71e739e50>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = train_generator.num_classes\n",
    "\n",
    "model = streets_sign_model(n_classes)\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(train_generator,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=val_generator,\n",
    "                callbacks=[ckpt_saver, early_stop]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 60, 60, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 58, 58, 32)        896       \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 56, 56, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 28, 28, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 28, 28, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 26, 26, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 13, 13, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 13, 13, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 21632)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                1384512   \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 43)                2795      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,481,323\n",
      "Trainable params: 1,480,939\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Evaluating validation set:\n",
      "62/62 [==============================] - 16s 242ms/step - loss: 0.0726 - accuracy: 0.9893\n",
      "Evaluating test set : \n",
      "198/198 [==============================] - 53s 266ms/step - loss: 0.3578 - accuracy: 0.9559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3578275740146637, 0.955898642539978]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tensorflow.keras.models.load_model('./Models')\n",
    "model.summary()\n",
    "\n",
    "print(\"Evaluating validation set:\")\n",
    "model.evaluate(val_generator)\n",
    "\n",
    "print(\"Evaluating test set : \")\n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def predict_with_model(model, imgpath):\n",
    "\n",
    "    image = tf.io.read_file(imgpath)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    image = tf.image.resize(image, [60,60]) # (60,60,3)\n",
    "    image = tf.expand_dims(image, axis=0) # (1,60,60,3)\n",
    "\n",
    "    predictions = model.predict(image) \n",
    "    predictions = np.argmax(predictions)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction = 21\n"
     ]
    }
   ],
   "source": [
    "img_path = \"C:\\\\Users\\\\RASWANTH.SR\\\\Desktop\\\\ML\\\\Neural Networks and Deep Learning\\\\Tensorflow for CV\\\\CSV\\\\Test\\\\28\\\\07827.png\"\n",
    "model = tf.keras.models.load_model('./Models')\n",
    "prediction = predict_with_model(model, img_path)\n",
    "print(f\"prediction = {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
